<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Beyond Raw Data</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Beyond Raw Data</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 04 Aug 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>EXPLORATORY DATA ANALYSIS</title>
      <link>/post/2019-08-04-exploratory-data-analysis/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-08-04-exploratory-data-analysis/</guid>
      <description>


&lt;blockquote&gt;
&lt;p&gt;“The goal is to turn data into information and information into insight.” – Carly Fiorina, former chief executive officer, Hewlett Packard.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;INTRODUCTION&lt;/h3&gt;
&lt;p&gt;If you are familiar with data analysis then I’m certain that you fully relate to the above statement. After all, it would be pointless to play around with lots of data just for the love of it.&lt;/p&gt;
&lt;p&gt;Data is gold, and the more you have the better off you are. However, raw unprocessed data is of no use unless you manipulate and gain insights from it. Before embarking on statistical modelling and visualization of your data, it is very important to first have an understanding of the data itself. Exploratory Data Analysis (&lt;strong&gt;EDA&lt;/strong&gt;) aids in visualization, transformation, and generally cleaning or remodeling data before diving deep into statistics and predictive modelling.&lt;/p&gt;
&lt;p&gt;There are not set rules to be followed when performing EDA. As a data reparation phase, one is allowed to decide what suits them best in order to gain an understanding of their data. However, there are two most important questions one should seek to answer while studying their data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is there variation within my variables?&lt;/li&gt;
&lt;li&gt;Is there any correlation between my variables?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That being said, EDA involves the following checks among others:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Descriptive Statistics&lt;/strong&gt; - Give a summarized understanding of the data, usually as measures of central tendency and variability.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mean&lt;/strong&gt; - Arithmetic average&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Median&lt;/strong&gt; - middle value&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mode&lt;/strong&gt; - most frequent value&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Standard Deviation&lt;/strong&gt; - variation from the mean&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kurtosis&lt;/strong&gt; -peakedness of the data distribution&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Skewness&lt;/strong&gt; - symmetry of the data distribution&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Groupings of data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Missing values&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ANOVA:&lt;/strong&gt; Analysis of variance&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Graphical visualization&lt;/strong&gt;, not restricted to:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Histogram&lt;/strong&gt; -frequency bar plots&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Density estimation&lt;/strong&gt; - an estimation if the frequency distribution based on sample data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Box plots&lt;/strong&gt; - A visual representation of median, quantiles, symmetry and ourtliers&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scatter plots&lt;/strong&gt; - a graphical display of variables plotted on the x and y axes.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this post, we will perform EDA on a sample data set containing responses on mobile banking survey in Kenya. If you would like to follow along with the same data, you can download it &lt;a href=&#34;https://github.com/CarlvinJerry/sources/blob/master/data/Mobile%20Banking%20in%20Kenya.csv&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-importation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Importation&lt;/h2&gt;
&lt;p&gt;The code chunk below imports our data set into R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Loading Data into R  toc_depth: 2
mobileBanking.Df &amp;lt;- read.csv(&amp;quot;J:\\Personalprojects\\Blogsite\\sources\\data\\Mobile Banking in Kenya.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE )
mobileBanking.Df &amp;lt;- mobileBanking.Df[,-1] #Remove the number column which is Irrelevant&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;data-inspection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1.0.0 Data Inspection&lt;/h3&gt;
&lt;p&gt;Once our sample data set loaded, we can check for features present in it. We first need to load all the libraries needed for data analysis and manipulation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; #Load required packages or install if not present.----
load.libraries &amp;lt;- c(&amp;#39;data.table&amp;#39;,&amp;#39;tidyverse&amp;#39;,&amp;#39;gridExtra&amp;#39;, &amp;#39;corrplot&amp;#39;, &amp;#39;GGally&amp;#39;, &amp;#39;ggplot2&amp;#39;, &amp;#39;e1071&amp;#39;, &amp;#39;dplyr&amp;#39;)
install.lib &amp;lt;- load.libraries[!load.libraries %in% installed.packages()]

for(libs in install.lib) install.packages(libs, dependences = TRUE)

#Load libraries and flag TRUE
sapply(load.libraries, require, character = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function above takes in a list of required libraries, checks if they are already installed and installs them if not. It then loads all the packages one at a go.&lt;/p&gt;
&lt;/center&gt;
&lt;figure&gt;
&lt;img class=&#34;pure-u-1-2&#34; src=&#34;https://carlvinjerry.github.io/post/MyImages/packages.png&#34; height=&#34;100%&#34; width=&#34;Auto&#34;&gt;
&lt;figcaption&gt;
Figure 1: Loaded packages
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/center&gt;
&lt;div id=&#34;observing-the-data-structure&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;1.1.0 Observing the data structure&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(mobileBanking.Df)
## [1] 43 11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data set has 43 rows with 11 Variables. We therefore explore the data types present in each variable column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Check Categorical VS Numeric Characters----
cat_vars &amp;lt;- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.character))]
cat_vars
##  [1] &amp;quot;Gender&amp;quot;                       &amp;quot;Age.Range&amp;quot;                   
##  [3] &amp;quot;Have.Bak.Account&amp;quot;             &amp;quot;Bank.account.connected.to.MB&amp;quot;
##  [5] &amp;quot;MB.used.for&amp;quot;                  &amp;quot;Importance&amp;quot;                  
##  [7] &amp;quot;Benefit&amp;quot;                      &amp;quot;Bank.Visit&amp;quot;                  
##  [9] &amp;quot;MB.Safety&amp;quot;                    &amp;quot;Influence&amp;quot;                   
## [11] &amp;quot;Satisfaction&amp;quot;

numeric_vars &amp;lt;- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.numeric))]
numeric_vars
## character(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To identify the data types, we can check for numeric and categorical variables present in the data. In our case, all the variables in our data set are categorical variables. We will therefore explore the data from a categorical approach rather than numeric. There exists different visualization methods for different data types. Now that we have established the general structure of the data, we can check if there are any missing values within the variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Checking data for any missing values
colSums(sapply(mobileBanking.Df, is.na))
##                       Gender                    Age.Range 
##                            0                            0 
##             Have.Bak.Account Bank.account.connected.to.MB 
##                            0                            0 
##                  MB.used.for                   Importance 
##                            0                            0 
##                      Benefit                   Bank.Visit 
##                            0                            0 
##                    MB.Safety                    Influence 
##                            0                            0 
##                 Satisfaction 
##                            0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have no NULL values in our data. We can therefore proceed to analysis without worrying about missing values. In a case whereby there exists null values, one can choose whether to replace the nulls with the most appropriate values or remove the rows with nulls from the data. This is important for later stages of analysis that include data modelling, like Machine Learning.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-summary&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;1.1.1 Data Summary&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Data Summary----
summary(mobileBanking.Df)
##     Gender           Age.Range         Have.Bak.Account  
##  Length:43          Length:43          Length:43         
##  Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character  
##  Bank.account.connected.to.MB MB.used.for         Importance       
##  Length:43                    Length:43          Length:43         
##  Class :character             Class :character   Class :character  
##  Mode  :character             Mode  :character   Mode  :character  
##    Benefit           Bank.Visit         MB.Safety        
##  Length:43          Length:43          Length:43         
##  Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character  
##   Influence         Satisfaction      
##  Length:43          Length:43         
##  Class :character   Class :character  
##  Mode  :character   Mode  :character&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;&lt;em&gt;Summary()&lt;/em&gt;&lt;/strong&gt; function comes in handy at summarizing data. I our case, there is no statistical measures since all our variables are categorical. Important to note that the function also specifies the specific data types. There are more than enough ways to inspect data structures in R.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-insights-from-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2.0.0 Getting Insights from the data&lt;/h3&gt;
&lt;div id=&#34;descriptive-statistics-for-categorical-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2.1.0 Descriptive Statistics For Categorical Data&lt;/h4&gt;
&lt;p&gt;The main goal of descriptive statistics is to inform data analysts on the main features of either numerical or categorical data, using sample summaries represented as either tables, individual numbers or charts and graphs. Since we only have categorical data, I will illustrate the most used forms of descriptive statistics for the same. However, like I mentioned earlier, there are more than enough ways to analyze data in R.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;div id=&#34;frequencies&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;2.1.1 Frequencies&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Frequencies&lt;/strong&gt; illustrate the number of occurrences or observations of a particular category in data. We use &lt;a href=&#34;https://en.wikipedia.org/wiki/Contingency_table&#34;&gt;contigency tables&lt;/a&gt; to present this information. In R this can be achieved using the &lt;strong&gt;&lt;em&gt;table()&lt;/em&gt;&lt;/strong&gt; function.&lt;/p&gt;
&lt;p&gt;From out data, the total distribution of respondents based on gender looks like this;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Gender frequencies
#library(kableExtra)
table(mobileBanking.Df$Gender)
## 
## Female   Male 
##     20     23&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can illustrate multiple attributes using cross classification tables such as;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#library(kableExtra)
# Cross classification counts for gender by Mobile banking safety opinion
table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety)
##         
##          NotAtAll Somewhat Very
##   Female        3       11    6
##   Male          0       19    4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Multidimensional tables with three or more categories can also be achieved using the &lt;strong&gt;&lt;em&gt;ftable()&lt;/em&gt;&lt;/strong&gt; . As an example, let’s check out the number of respondents based on gender, mobile banking safety opinion and how often they visit the bank.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Counts by gender, opinion and bank visits
table_ &amp;lt;- table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety, mobileBanking.Df$Bank.Visit)
ftable(table_)
##                  FewTimesAyear OnceMonth
##                                         
## Female NotAtAll              3         0
##        Somewhat             11         0
##        Very                  5         1
## Male   NotAtAll              0         0
##        Somewhat             15         4
##        Very                  4         0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;proportions&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;2.1.1 Proportions&lt;/h5&gt;
&lt;p&gt;Proportions are basically contingency tables represented as percentages. From our previous tables, we can do proportions for the same by applying &lt;strong&gt;&lt;em&gt;prop.table()&lt;/em&gt;&lt;/strong&gt; to output produced by the *&lt;strong&gt;table()&lt;/strong&gt; function. Proportions for the above will then be;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#library(kableExtra)
#Gender frequencies proportions
prop.table(table(mobileBanking.Df$Gender))
## 
##    Female      Male 
## 0.4651163 0.5348837

#Percentage idistribution for Gender by mobile banking safety
prop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety))
##         
##            NotAtAll   Somewhat       Very
##   Female 0.06976744 0.25581395 0.13953488
##   Male   0.00000000 0.44186047 0.09302326

#Percentage by gender, opinion and bank visits, rounding off to 2 decimal places
table_ &amp;lt;- table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety, mobileBanking.Df$Bank.Visit)
ftable(round(prop.table(table_),2))
##                  FewTimesAyear OnceMonth
##                                         
## Female NotAtAll           0.07      0.00
##        Somewhat           0.26      0.00
##        Very               0.12      0.02
## Male   NotAtAll           0.00      0.00
##        Somewhat           0.35      0.09
##        Very               0.09      0.00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;marginals&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;2.1.2 Marginals&lt;/h5&gt;
&lt;p&gt;Marginals measure counts across columns or rows in a contingency table. &lt;strong&gt;&lt;em&gt;Margin.table()&lt;/em&gt;&lt;/strong&gt; gives us the frequencies while &lt;strong&gt;&lt;em&gt;prop.table()&lt;/em&gt;&lt;/strong&gt; gives us the percentages. Using our previous examples on frequencies;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# FREQUENCY MARGINALS
# row marginals - totals for each gender across mobile banking opinion
margin.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), 1)
## 
## Female   Male 
##     20     23

# colum marginals -  totals for each gender across mobile banking opinion
margin.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), 2)
## 
## NotAtAll Somewhat     Very 
##        3       30       10

# PERCENTAGE MARGINALS
# row marginals - row percentages across gender
prop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), margin = 1)
##         
##          NotAtAll Somewhat     Very
##   Female 0.150000 0.550000 0.300000
##   Male   0.000000 0.826087 0.173913

# colum marginals - column percentages acrossmobile banking opinion
prop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), margin = 2)
##         
##           NotAtAll  Somewhat      Very
##   Female 1.0000000 0.3666667 0.6000000
##   Male   0.0000000 0.6333333 0.4000000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-distributions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2.2.0 Visualizing Distributions&lt;/h4&gt;
&lt;p&gt;The code chunk bellow is a function that takes in our data set and plots all the present variables in it. Since we have categorical variable only, we will use &lt;strong&gt;bar plots&lt;/strong&gt; for visualization. They are the most appropriate for categorical data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Loading Data into R  toc_depth: 2
mobileBanking.Df &amp;lt;- read.csv(&amp;quot;J:\\Personalprojects\\Blogsite\\sources\\data\\Mobile Banking in Kenya.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE )
mobileBanking.Df &amp;lt;- mobileBanking.Df[,-1] #Remove the number column which is Irrelevant

#Check Categorical VS Numeric Characters----
cat_vars &amp;lt;- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.character))]
numeric_vars &amp;lt;- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.numeric))]


####Convert character to factors----
library(data.table)
setDT(mobileBanking.Df)[,(cat_vars) := lapply(.SD, as.factor), .SDcols = cat_vars]

mobileBanking.Df_cat &amp;lt;- mobileBanking.Df[,.SD, .SDcols = cat_vars]
    ##mobileBanking.Df_cont &amp;lt;- mobileBanking.Df[,.SD,.SDcols = numeric_vars]

#Functions for Plots---
library(ggplot2)
library(gridExtra)
plotHist &amp;lt;- function(data_in, i) {
  data &amp;lt;- data.frame(x=data_in[[i]])
  p &amp;lt;- ggplot(data=data, aes(x=factor(x))) + stat_count() + xlab(colnames(data_in)[i]) + theme_light() + 
    theme(axis.text.x = element_text(angle = 90, hjust =1))
  return (p)
}

doPlots &amp;lt;- function(data_in, fun, ii, ncol=3) {
  pp &amp;lt;- list()
  for (i in ii) {
    p &amp;lt;- fun(data_in=data_in, i=i)
    pp &amp;lt;- c(pp, list(p))
  }
  do.call(&amp;quot;grid.arrange&amp;quot;, c(pp, ncol=ncol))
}

plotDen &amp;lt;- function(data_in, i){
  data &amp;lt;- data.frame(x=data_in[[i]], SalePrice = data_in$SalePrice)
  p &amp;lt;- ggplot(data= data) + geom_line(aes(x = x), stat = &amp;#39;density&amp;#39;, size = 1,alpha = 1.0) +
    xlab(paste0((colnames(data_in)[i]), &amp;#39;\n&amp;#39;, &amp;#39;Skewness: &amp;#39;,round(skewness(data_in[[i]], na.rm = TRUE), 2))) + theme_light() 
  return(p)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variable-distributions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Variable Distributions&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Plotting categorical values----
#Bar plots
doPlots(mobileBanking.Df_cat, fun = plotHist, ii = 1:4, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-04-exploratory-data-analysis_files/figure-html/barplots1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;gender&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Gender&lt;/h3&gt;
&lt;p&gt;It can be seen that a larger number of respondents were male, this is however by a small margin. If we had a larger data set we could have more female respondents.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;div id=&#34;age-range&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Age Range&lt;/h4&gt;
&lt;p&gt;A majority of respondents were younger guys between age &lt;strong&gt;21-30&lt;/strong&gt;, followed by the &lt;strong&gt;31-40&lt;/strong&gt; age bracket. The least respondents were those above age &lt;strong&gt;41&lt;/strong&gt;. This could be probably because the older people chose not to participate in the survey as opposed to the younger ones, or that they somehow never got to opportunity to do so. A good example is the medium by which the survey was conducted, which the older people didn’t have.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;div id=&#34;have-bank-account-linked-to-mobile-banking&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Have Bank Account &amp;amp; Linked To Mobile Banking&lt;/h5&gt;
&lt;p&gt;All the respondents had bank accounts. A very small number had their business bank accounts linked to mobile banking. Majority had linked their current accounts probably due to the convenience that comes with mobile banking like frequent or timeless withdrawals.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-04-exploratory-data-analysis_files/figure-html/barplots2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;div id=&#34;uses-of-mobile-banking-importance-and-benefits&#34; class=&#34;section level6&#34;&gt;
&lt;h6&gt;Uses Of Mobile Banking, Importance And Benefits&lt;/h6&gt;
&lt;p&gt;Most respondents use mobile banking services for making payments. this is followed by cash withdrawals. Airtime purchase and money transfer happen to be the least uses for the service. This could be because they are easily accessible needs unlike cash withdrawal and making payments in terms of mobility convenience.&lt;/p&gt;
&lt;p&gt;Most respondents found mobile banking services &lt;strong&gt;very important&lt;/strong&gt;, probably owing to the affordable cost charges and good service which could mean less usability issues when using the services.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-08-04-exploratory-data-analysis_files/figure-html/barplots3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bank-visits&#34; class=&#34;section level6&#34;&gt;
&lt;h6&gt;Bank Visits&lt;/h6&gt;
&lt;p&gt;We had most users who visit their banks a few times a year while the least do it once a month. This means that generally, fewer people visit the bank physically. This could be a major impact of mobile banking services.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mobile-banking-safety-influence-and-satisfaction&#34; class=&#34;section level6&#34;&gt;
&lt;h6&gt;Mobile Banking Safety, Influence And Satisfaction&lt;/h6&gt;
&lt;p&gt;Despite being majorly satisfied by the services, most respondents did not find mobile banking services very safe. It is also seen as time saving which is probably why we had very few bank visits in general.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion-from-variable-distributions&#34; class=&#34;section level6&#34;&gt;
&lt;h6&gt;Conclusion from variable distributions&lt;/h6&gt;
&lt;p&gt;It can be concluded that mobile banking is mainly preferred by younger people, a majority being of the male gender. However, the only benefit most users find from mobile banking seems to be the convenience it brings. Safety is still a major concern.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;That’s basically it for exploratory data analysis. I made sure to cover the basics, meaning there’s still much to be added on to this; more visualizations, &lt;a href=&#34;https://www.researchgate.net/post/What_are_the_best_R_packages_for_exploratory_data_analysis_of_psychological_data&#34;&gt;packages&lt;/a&gt; that simplify the whole process etc…This is to be continued. For a detailed documentation on the same, &lt;a href=&#34;https://r4ds.had.co.nz/index.html&#34;&gt;here’s&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hadleywickham?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor&#34;&gt;Hadley Wickham’s&lt;/a&gt; &lt;strong&gt;R for Data Science&lt;/strong&gt; book you can use as a reference point.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;https://fontmeme.com/permalink/190129/8b378e9ce35b7a28dd150c4f1d656807.png&#34; /&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
            <category>Data Visualization</category>
      
            <category>R</category>
      
      
            <category>Data Analytics</category>
      
            <category>R</category>
      
    </item>
    
    <item>
      <title>DATA MINING IN R</title>
      <link>/post/2019-01-25-r-data-mining-rmd/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-01-25-r-data-mining-rmd/</guid>
      <description>


&lt;p&gt;#PartI{#PartI}
&amp;gt;This first section assumes you have no knowledge in building a twitter app to be used for fetching data. You can skip directly to &lt;a href=&#34;#PartII&#34;&gt;the second section here&lt;/a&gt; if you are able to build your own twitter app and get the required authentication keys.&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction:&lt;/h3&gt;
&lt;p&gt;Social media usage has grown rapidly over the past few decades. Most social networks we can think of now are so well established, making them a platform where people can not only talk to one another but also be able to come forward with different views and interests they would like to express. With an almost constant rate of increasing users each day, social networks such as Facebook and Twitter have become great sources of data which can be used in the broad field of Data Science:Talk of (those pretty annoying) targeted ads for example…&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;https://media.giphy.com/media/3o6Mbmg6AchRmB4ylO/giphy.gif&#34; alt=&#34;Gif: They just keep coming!!&#34; /&gt;
&lt;center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;With the help of APIs, we are easily able to get data from such platforms to be used for further analysis. In this article we will go through the first step of text mining in R using data fetched from Twitter. The main advantage of these APIs is that the data we will fetch comes in a well-structured format which makes our work easier when crunching. In this case we will use the readily available Twitter API and create our own Twitter app that will then help in fetching the data. The following steps will accomplish the task…&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-a-twitter-app&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating a Twitter app&lt;/h3&gt;
&lt;p&gt;To create a twitter app we can use for fetching metadata, we first need to have a Twitter account. We then need to go to the &lt;strong&gt;twitter dev site&lt;/strong&gt; &lt;a href=&#34;https://developer.twitter.com/&#34; class=&#34;uri&#34;&gt;https://developer.twitter.com/&lt;/a&gt; and log in with our user account.
On the top right corner should be a drop down menu next to your username, go to APPS. At this point if you are doing this for the first time your Apps section should be blank. Click on “Create an app” to… create an app.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;https://carlvinjerry.github.io/post/MyImages/apps.PNG&#34; alt=&#34;Figure 1: App login&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;We then have to fill in the form below appropriately. Here is a breakdown of what’s required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Name:&lt;/strong&gt;
Give your app a unique name of your choice, e.g &lt;strong&gt;UniqueName&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description:&lt;/strong&gt;
This can always be changed later, use this to provide a brief note on what your app is all about to be able to distinguish it from other apps you might create in future.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Website:&lt;/strong&gt;
This should be your application’s home page web site. It is however not applicable for most personal apps. Anything goes here e.g &lt;a href=&#34;https://carlvinjerry.github.io&#34; class=&#34;uri&#34;&gt;https://carlvinjerry.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Callback URL:&lt;/strong&gt;
I would ignore the Callback URL field. If you are allowing users to log into your app to authenticate themselves, you’d enter the URL where they would be returned after they’ve given permission to Twitter to use your app.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&#34;https://carlvinjerry.github.io/post/MyImages/apps2.PNG&#34; alt=&#34;Figure 2: Create an app&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The remaining fields should be quite straight forward but must be filled. Click “Create” once done and there you have your first twitter app.
On your app is a menu with &lt;strong&gt;Keys and tokens&lt;/strong&gt;. These are the most important components since we will need them to access data from the APIs.Generate both consumer and access tokens (if not readily available) and take note of them. &lt;strong&gt;NB:&lt;/strong&gt; &lt;strong&gt;These keys are meant for your eyes only!&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;https://CarlvinJerry.github.io/post/MyImages/keys.PNG&#34; alt=&#34;Figure 3: API Keys&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The final bit of setting up our twitter app is granting access permissions. We will mostly do fine with the &lt;strong&gt;read-only&lt;/strong&gt; if all we need is to fetch data but it can always be changed later.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;https://carlvinjerry.github.io/post/MyImages/permisions.PNG&#34; alt=&#34;Figure 4: Permissions&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Now we can move on to the next step where we set up &lt;strong&gt;R&lt;/strong&gt; to query data from Twitter.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;#PartII{#PartII}
## Setting up R to fetch twitter data
With our twitter app set up &lt;a href=&#34;#PartI&#34;&gt;in part I above&lt;/a&gt; and we are able to get the authentication keys for the API, we can now easily fetch data from twitter in R. The following steps will help us do this:&lt;/p&gt;
&lt;div id=&#34;prerequisites&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Prerequisites:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Twitter API Keys:&lt;/strong&gt; At this point we already have our twitter app with the required API keys.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;R and an IDE of choice:&lt;/strong&gt; We also need to have R installed, advisably the latest version. Microsoft’s &lt;a href=&#34;https://mran.microsoft.com/open&#34;&gt;&lt;strong&gt;enhanced R distribution&lt;/strong&gt;&lt;/a&gt; is recommended over the
&lt;a href=&#34;https://cran.r-project.org/bin/windows/base/&#34;&gt;&lt;strong&gt;base R&lt;/strong&gt;&lt;/a&gt; but for this specific task either can do just fine. I would recommend &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/&#34;&gt;&lt;strong&gt;R STUDIO&lt;/strong&gt;&lt;/a&gt; for an &lt;strong&gt;IDE&lt;/strong&gt;. One obvious advantage of all these is that they’re open-source tools.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;install-and-load-the-required-packages-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1.Install and Load the required packages in R&lt;/h3&gt;
&lt;p&gt;R has a standard set of packages, each with different tasks. You can find some packages for download&lt;br /&gt;
&lt;a href=&#34;https://cran.cnr.berkeley.edu/&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;. The code chunk below installs and loads the specific packages we need for this task. Take note of comments at each line of code, initiated by an octothorp.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Install packages
install.packages(&amp;quot;twitteR&amp;quot;)#------Extracts data from twitter
install.packages(&amp;quot;httr&amp;quot;)#--------Tools for Working with URLs and HTTP&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#We can now load the two packages 
library(&amp;quot;twitteR&amp;quot;)
require(&amp;quot;httr&amp;quot;)#-------------Both require() and library() can be used to call an installed package&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; Windows users might need to download a certification file and store it in the working directory. This certificate file initiates a handshake between R and the Twitter API.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Download &amp;quot;cacert.pem&amp;quot; file
download.file(url=&amp;quot;https://curl.haxx.se/ca/cacert.pem&amp;quot;,destfile=&amp;quot;cacert.pem&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-and-store-objects-containing-the-twitter-authenticated-credentials&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2.Create and store objects containing the twitter authenticated credentials&lt;/h3&gt;
&lt;p&gt;This is where we invoke the twitter API using the credentials from our app and query the data we need.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Authentication keys
consumer_key &amp;lt;- &amp;#39;hjksdha08097afnjhaa90uaf&amp;#39;
consumer_secret &amp;lt;- &amp;#39;hjksdha08097afnjhaa90uaf&amp;#39;
access_token &amp;lt;- &amp;#39;hjksdha08097afnjhaa90uaf&amp;#39;
access_secret &amp;lt;- &amp;#39;hjksdha08097afnjhaa90uaf&amp;#39;

#The above tokens are what we made the twitter app for.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;query-data-from-twitter&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;3.Query data from twitter&lt;/h3&gt;
&lt;p&gt;We can now go ahead and fetch our data. Due to limitations on the twitter standard apps, it is advisable to store your data in R locally. This will reduce the number of times you have to make requests to twitter to fetch data. You will therefore do much more with your app that way regardless of the limitations- Or you can as well buy the premium app. In my example below, I am fetching data for a user on twitter called &lt;span class=&#34;citation&#34;&gt;@UKenyatta&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Connect to Twitter 
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
tweets &amp;lt;- userTimeline(&amp;quot;UKenyatta&amp;quot;, n=3200) #Standard twitter apps are limited to 3200 tweets per                                                  #download session. This could come out less depending on
                                            #the app

#create a data frame of the tweets
UKenyatta_Tweets &amp;lt;- tbl_df(map_df(tweets, as.data.frame))

# Save tweets for later (and note when saved):
save(UKenyatta_Tweets, file=&amp;quot;UKenyatta_Tweets.RData&amp;quot;)

# You can then access them later at will...
# load(&amp;quot;UKenyatta_Tweets.RData&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can now manipulate your data and see what you find out.&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;https://media.giphy.com/media/ZtMkorgeyRu5q/giphy.gif&#34; alt=&#34;Happy crunching!!&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;https://fontmeme.com/permalink/190129/8b378e9ce35b7a28dd150c4f1d656807.png&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
      
            <category>Twitter</category>
      
            <category>Data Mining</category>
      
            <category>R</category>
      
            <category>Data Visualization</category>
      
            <category>Sentiment Analysis</category>
      
      
            <category>Data Mining</category>
      
            <category>R</category>
      
    </item>
    
  </channel>
</rss>