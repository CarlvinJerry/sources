--- 
title: "Password Etiquette"
summary: "Lessons and observations from week 3 of 2020's #TidyTuesday challenge"
subtitle: "The dos and don'ts of creating passwords and why you need a password manager"
disable_comments: false # Optional, enable Table of Contents for specific post

authors: 
- admin
date: '2020-05-29'
featured: true
image:
  caption: 'Image credit: [**Photo by Markus Winkler on Unsplash**](https://unsplash.com/photos/OjSG0E_qcbo)'
  focal_point: ""
  placement: 3
  preview_only: true
output: md_document
lastmod: "2020-05-29T17:51:00+03:00"
projects: [Tidy Tuesday]
categories: [R, Data Visualization]

tags: [TidyTuesday, R, Data Visualization]

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

>I got bitten by the famous procrastination bug earlier this year, so I missed out on #TidyTuesday's week 3(2020) challenge. As a make-up, I thought I should do it here instead and maybe someone will learn one or two things about security, digital privacy to  be precise. 

### INTRODUCTION
Exposing ourselves to cyber attacks comes as easy as having access to the internet. Almost every website you visit will require you to create an account to be able to access significant information or services from them - So where exactly does the problem with password strength begin? Memory methinks...  

The whole purpose of memory is to preserve information. Events, names, faces, mathematical formulae etcetera, all seem recorgnizable every time we recollect because the mind memorizes them. I don't know how exactly remembering works, but you will agree with me on this; the memory is sometimes very unreliable when it comes to cramming passwords. It is for this very reason that, in the quest for memorizing our passwords, we find ourselves using weak passwords.  

Different folk memorize passwords differently; some of us share passwords across platforms (very counter intuitive if you actually think about it re cyber security), some use personal information such as names, birthdays, spouse names(ha!) and what have you. My point is, we cannot fully trust ourselves to match brute force algorithms trying to hack their way into our facebook(s), instagram(s) and worse for me, online banking and credit card acconts. So here are a few Ps and Qs for setting up passwords.  

>Small task [here](https://howsecureismypassword.net/), check how long it would take a computer to crack your bank account password.

I used [#TidyTuesday's passwords](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-14/readme.md) data for illustration. To keep it concise, all the code used in this hidden, click the ```CODE``` button to expand if you wish to see the code. Shout out to my good friend and avid data analyst Martin who helped in building a password strength metter used in ranking passwords used here, you can read more on the tool (here)[https://ndirangumartin.netlify.app/post/password-meter-in-r/]. That being said, let's get visual.  

The graph bellow show a scattered distribution of a small fraction of our compromised passwords. You want to ensure that if your passwords happen to be on this chart, they are on the bottom far left of the chart i.e, the passwords are unique and exhibit stronger strengths. That way, you know that even a computer will take quite some time before cracking it. The further and lower it is along the x-axis, the greener and stronger it is. 



####https://xkcd.com/936/

# Data Importation
The code chunk below imports, cleans and generates the chart from the data.
```{r chatterPlot, warning=FALSE, include=FALSE, results=FALSE}
#load packages
library(readr)
library(dplyr)
library(tidyr)
#library(tidyverse)
library(devtools)
library(remotes)
library(ggplot2)
library(ggrepel)
library(ggplot2)
library(ggrepel)
library(scales)


#The Data...
#Read Kaggle data for compromised passwords
#dataset <- read.csv("compromised.csv", stringsAsFactors = FALSE)
dataset <- read.csv("J:/Personalprojects/Blogsite/sources/content/post/password-etiquette/compromised.csv", stringsAsFactors = FALSE)

#Read #TidyTuesday data
passwords <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-14/passwords.csv')

#Subset, bind password cols and check data
passwordDf = data.frame(Password = c(passwords$password,dataset$X0), stringsAsFactors = FALSE)
nrow(passwordDf) #Check rows to confirm new dataset

#remove nulls
passDf <- passwordDf %>% drop_na(Password)
nrow(passDf) #Check rows to confirm new dataset

#Save new dataSet
#write.csv(passDf,"J:/Personalprojects/Blogsite/sources/content/post/password-etiquette/compromisedPasswords.csv")

#Analysis
#Unique=========================================
uniques <- length(unique(passDf))
uniques

#Duplicates=============================
# duplicates <- length(passDf[duplicated(passDf)])
# duplicates

#Rankings======================================================
#Top 10 Passwords
#Counts
head(sort(table( passDf$Password ), decreasing = T),10)

#Percentages
head(sort(prop.table(table(passDf$Password)), decreasing = T),10)

#Tables

#Base words ====================
# library(tm)
# docs <- tm_map(docs, removeWords, stopwords("english"))
# 
# 

# 2. Number of characters
Passwordlength <- nchar(passDf$Password)

freq <- as.data.frame(table(Passwordlength))
sum(freq$Freq)

# 
# #plot1 number of characters distribution
# data2 <- data.frame(x = freq$Passwordlength, y = freq$Freq)
# 
# 
# plot1_CharactersDist <- ggplot(data2, aes(x = data2$x, y = data2$y)) +
#   geom_segment(aes(x = data2$x, xend = data2$x, y = 0, yend = data2$y), 
#                color = ifelse( data2$x %in% c(6,8), 'orange1','grey69'),
#                size = ifelse( data2$x %in% c(6,8), 1.3,0.5)) +
#   geom_point( size = ifelse( data2$x %in% c(6,8), 3,2),
#               color = ifelse( data2$x %in% c(6,8), 'orange1','grey69')) + 
#   theme_light() +
#   theme(
#     plot.background = element_rect(fill = "grey4"),
#     panel.background = element_rect(fill = 'grey4'),
#     panel.grid.major.x = element_blank(),
#     #panel.grid.minor.x = element_blank(),
#     panel.grid.major.y = element_line( size = .012, linetype = "dashed", colour = "grey"), # element_blank(),#
#     panel.grid.minor.y = element_blank(),# element_line( size = .1, linetype = "dashed"),
#     #panel.border = element_blank(),
#     axis.ticks.x = element_blank(),
#     axis.ticks.y = element_blank(),
#     plot.title = element_text( hjust = 0.5, vjust = 0, colour = 'grey'),
#     axis.text.x = element_text(colour = 'grey'),
#     axis.text.y = element_text(colour = 'grey', angle = 90, hjust = 0.5),
#     axis.title.x = element_text(colour = 'grey'),
#     axis.title.y = element_text(colour = 'grey')
#   ) +
#   xlab('Password Length') +
#   ylab('Frequency') 
# 
# plot1_CharactersDist +
#   annotate("text", x = data2$x[which(data2$x == 6)], y = data2$y[which(data2$x == 6)]*1,
#            label = paste("6 characters(Minimum recommended)\n (val=",data2$y[which(data2$x == 6)] %>% round(2),")",sep = "" ),
#            color = "firebrick4",size = 3.3, angle = 0, fontface = "italic", hjust = -0.05) +
#   annotate("text", x = data2$x[which(data2$x == 7)], y = data2$y[which(data2$x == 7)]*1,
#            label = paste("7 Characters\n (val=",data2$y[which(data2$x == 7)] %>% round(2),")",sep = "" ), 
#            color = "orchid4", size = 3.3, angle = 0, fontface = "italic", hjust = -0.05) +
#   annotate("text", x = data2$x[which(data2$x == 8)], y = data2$y[which(data2$x == 8)]*1,
#            label = paste("8 Characters(Recommended by most websites)\n (val=",data2$y[which(data2$x == 8)] %>% round(2),")",sep = "" ), 
#            color = "palegreen4", size = 3.3, angle = 0, fontface = "italic", hjust = -0.05) +
#   annotate("text", x = data2$x[which(data2$x == 0:5)], y = data2$y[which(data2$x == 0:5)]*1,
#            label = paste("\n ",data2$y[which(data2$x == 0:5)] %>% round(2),"",sep = "" ), 
#            color = "firebrick3", size = 3.3, angle = 90, fontface = "italic", hjust = -0.05, vjust = 0.05) +
#   annotate("text", x = data2$x[which(data2$x %in% c( 9:41))], y = data2$y[which(data2$x %in% c( 9:41))]*1,
#            label = paste("\n ",data2$y[which(data2$x %in% c( 9:41))] %>% round(2),"",sep = "" ), 
#            color = "palegreen4", size = 3.3, angle = 90, fontface = "plain", hjust = -0.05, vjust = 0.1) +
#   # annotate("rect", xmin = data2$x[which(data2$x == 6)], xmax = data2$x[which(data2$x == 41)], ymin = 0, ymax = 0,
#   #            fill = 'green', alpha = .5) +
#   # annotate("rect", xmin = data2$x[which(data2$x == 0)], xmax = data2$x[which(data2$x == 6)], ymin = 0, ymax = 0,
#   #          fill = 'red', alpha = 1) +
#   # annotate("segment", x = 7, xend = 10, y = 5000,
#   #          yend = 5000, colour = "green", size = 0.5, alpha = 0.25) +
#   # annotate("segment", x = 3, xend = 7, y = 5000,
#   #          yend = 5000, colour = "red", size = 0.5, alpha = 0.25)
#   ggtitle("Distribution Of Number Of Characters in Passwords") 
# 
# #dev.off()
# 
# 


###PASSWORD STRENGTH ALGO
library(stringi)
library(stringr)

passMark <- function(passwords){
  #Additions
  #Number of characters----
  numChars = nchar(passwords)
  
  #Upper case letters ----
  upperCase = stringi::stri_count(passwords, regex  = "[A-Z]")
  
  #Lower case letters ----
  lowerCase = stringi::stri_count(passwords, regex  = "[a-z]")
  
  #Numbers----
  nums = stringi::stri_count(passwords, regex  = "[0-9]")
  
  #symbols
  symbols = c("~", "!", "@", "#", "\\$", "%", "\\^", "&", "\\*", "\\(" ,"\\)", "-", "\\+", "\\_", "=", "`" ,
              "\\{" ,"\\}" ,"\\[" ,"\\]",":", ";" , "<" , ">", "\\?" ,"," ,"\\.", "\\'", "@", "#", noquote("\""))
  
  num_symbols = stringr::str_count(passwords, paste(symbols, collapse = "|"))
  
  
  #In the Middle numbers
  midnums = stringi::stri_count(gsub('^.|.$', '', passwords), regex  = "[0-9]")
  
  #middle symbols
  
  mid_symbols = stringr::str_count(gsub('^.|.$', '', passwords), paste(symbols, collapse = "|"))
  
  requirements = c(upperCase, lowerCase, nums, num_symbols)
  
  requirements_score = 0
  for (i in requirements) {
    if(i > 0) requirements_score = requirements_score + 1 
  }
  
  requirements_score = ifelse(numChars < 8, 0, ifelse((requirements_score) < 3, 0, (requirements_score + 1)))
  
  character_count_score = (numChars * 4)
  uppercase_score = ifelse(upperCase == 0, 0, ((numChars - upperCase)*2))
  lowercase_score = ifelse(lowerCase == 0, 0, ((numChars - lowerCase)*2))
  numbers_score = ifelse(upperCase > 0 | lowerCase > 0 | num_symbols > 0, (nums * 4), 0) 
  symbols_score = (num_symbols * 6)
  mid_nums_symbol_score = ((midnums + mid_symbols) * 2)
  requirements_score = requirements_score * 2
  
  summed = 0 + character_count_score + uppercase_score + lowercase_score + numbers_score + symbols_score + mid_nums_symbol_score + requirements_score
  
  #Deductions
  #letters only
  letters_only = ifelse(numChars == (upperCase + lowerCase), numChars, 0)
  
  #numbers only
  numbers_only = ifelse(numChars == (nums), numChars, 0)
  
  split_function = function(password){
    password = str_extract_all(password, paste(c("[a-z]", "[A-Z]", "[0-9]", symbols), collapse = "|"))
    password = password[[1]]
    return(password)
  }
  
  #consecutive upper
  split_pass = split_function(passwords)
  consecutive_upper = ifelse(split_pass %in% LETTERS, 1, 0)
  r = rle(consecutive_upper)
  consecutive_upper = (r$lengths[r$values == 1]) - 1
  consecutive_upper = sum(consecutive_upper)
  
  #consecutive lower
  split_pass = split_function(passwords)
  consecutive_lower = ifelse(split_pass %in% letters, 1, 0)
  r = rle(consecutive_lower)
  consecutive_lower = (r$lengths[r$values == 1]) - 1
  consecutive_lower = sum(consecutive_lower)
  
  #Consecutive numbers
  split_pass = split_function(passwords)
  consecutive_numbers = ifelse(split_pass %in% (0:9), 1, 0)
  r = rle(consecutive_numbers)
  consecutive_numbers = (r$lengths[r$values == 1]) - 1
  consecutive_numbers = sum(consecutive_numbers)
  
  
  #Sequence checker function
  sequence_checker = function(split_pass, var_type) {
    
    if(var_type == "number"){
      
      sequence_check = as.integer(ifelse(split_pass %in% (0:9), split_pass, 0))
      
    } else if (var_type == "symbols"){
      
      sequence_check = ifelse(split_pass %in% symbols[1:13], match(split_pass, symbols[1:13]), 0)
      
    } else {
      
      sequence_check = ifelse(tolower(split_pass) %in% letters, match(tolower(split_pass), letters), 0)
      
    }
    sequence_check = abs(diff(sequence_check))
    sequence_check = ifelse(sequence_check == 1, 1, 0)
    r = rle(sequence_check)
    sequence_check = (r$lengths[r$values == 1]) - 1
    sequence_check = sum(sequence_check)
    return(sequence_check)
  }
  
  #letter sequence
  sequence_letters = sequence_checker(split_pass, "letters")
  
  #num sequence
  sequence_num = sequence_checker(split_pass, "number")
  
  #symbols
  sequence_symbols = sequence_checker(split_pass, "symbols")
  
  
  letters_only_score = letters_only
  numbers_only_score = numbers_only
  consecutive_upper_score = consecutive_upper * 2
  consecutive_lower_score = consecutive_lower * 2
  consecutive_numbers_score = consecutive_numbers * 2
  sequence_letters_score = sequence_letters * 3
  sequence_num_score = sequence_num * 3
  sequence_symbols_score = sequence_symbols * 3
  
  deductions = letters_only_score +
    numbers_only_score +
    consecutive_upper_score + 
    consecutive_lower_score + 
    consecutive_numbers_score +
    sequence_letters_score + 
    sequence_num_score +
    sequence_symbols_score
  
  total_score = ifelse((summed - deductions) < 0 , 0, ifelse((summed - deductions) > 100, 100, (summed - deductions)))
  
  # return(c(paste("Additions\nNumber of characters", character_count_score, sep = ": ") ,
  #          paste("\nUpper case characters", uppercase_score, sep = ":"),
  #          paste("\nLower case characters", lowercase_score, sep = ": "),
  #          paste("\nNumbers", numbers_score, sep = ": "),
  #          paste("\nSymbols", symbols_score, sep = ": "),
  #          paste("\nMiddle Numbers and symbols", mid_nums_symbol_score, sep = ": "),
  #          paste("\nRequirements", requirements_score, sep = ": "),
  #          paste("\n\nDeductions", sep = ""),
  #          paste("\nLetters only", letters_only_score, sep = ": "),
  #          paste("\nNumbers only", numbers_only_score, sep = ": "),
  #          paste("\nConsecutive upper", consecutive_upper_score, sep = ": "),
  #          paste("\nConsecutive lower", consecutive_lower_score, sep = ": "),
  #          paste("\nConsecutive numbers", consecutive_numbers_score, sep = ": "),
  #          paste("\nSequence letters", sequence_letters_score, sep = ": "),
  #          paste("\nSequence numbers", sequence_num_score, sep = ": "),
  #          paste("\nSequence symbols", sequence_symbols_score, sep = ": "),
         return(paste("", total_score))
  
  
}



#Subset data randomly to get 1500 passwords for strenght measure
df<-sample_n(passDf, 1000)



strenghtdf <- df %>% select(Password) %>% mutate(Strength = passMark(Password)) 

#ChatterPlot

```

#### 1.0.0 Data Inspection
Once our sample data set is loaded, we check for features present. We first need to load all the libraries needed for data analysis and manipulation.

```{r ChatterPlot, echo=FALSE}

word_counts <- passDf %>% count(Password, sort = T) %>% data.frame(stringsAsFactors = FALSE) 
chatterplotDf <- word_counts %>% rowwise()  %>% mutate(Strength = as.numeric(passMark(Password)))

#write.csv(chatterplotDf,"J:/Personalprojects/Blogsite/sources/content/post/password-etiquette/chattrplotdf.csv")




set.seed(42)

p =  head(chatterplotDf,200)  %>% ggplot(aes( Strength,n, label = Password)) +
   # ggrepel geom, make arrows transparent, color by rank, size by n
   geom_text_repel(segment.alpha = 0,aes(colour = Strength, size=n)) +
#Scale the axes/log transform 
 coord_trans(x="log2", y="log2") +
  # ggrepel geom, make arrows transparent, color by rank, size by n
  #geom_text(aes(colour=Strength, size=n)) + 
  # set color gradient, customize legend
  scale_color_gradient(low="red2", high="green4", 
                       guide = guide_colourbar(direction = "vertical",
                                               title.position = "top",
                                               frame.colour = "black",
                                               ticks.colour = "white",
                                               label.theme = element_text(colour = "white"),
                                               title.theme = element_text(colour = "white"),
                                               barwidth = .2,
                                               barheight = 20, 
                                               )) + 
  # set word size range & turn off legend
  scale_size_continuous(range = c(1, 10),
                        guide = FALSE) + 
  ggtitle(paste0("Top 200 passwords from ",
                 nrow(chatterplotDf),   # dynamically include row count
                 " compromised passwords, by frequency"),
          subtitle = "Password frequency (size) ~ password strength (color)") + 
  labs(y = "Password Frequency  (log scale)", x = "Password Srength (log scale)") 

#theme
p2 <- p + theme(panel.background =  element_rect(fill = "gray4", color = NA),
        panel.grid = element_blank(),
        plot.background = element_rect(fill = "gray4", color = NA),
        panel.grid.major.x = (element_line(color = "grey40",
                                           size = 0.25,
                                           linetype = "dotted")),
        panel.grid.major.y = element_line(color = "grey40",
                                          size = 0.1,
                                          linetype = "dotted"),
        # Change axis line
        axis.line = element_line(colour = "white"),
        axis.text = element_text(colour = "white"),
        axis.title = element_text(size = 10,
                                  colour = "white"),
        plot.title = element_text(colour = "white",
                                  face = "bold",
                                  size = 14),
        plot.subtitle = element_text(face = "italic",
                                     size = 10,
                                     colour = "white"),
        legend.background = element_blank())
p2

#Save plot
#ggsave(file="ptest.svg", plot=p2, width=10, height=8)


```

The function above takes in a list of required libraries, checks if they are already installed and installs them if not. It then loads all the packages one at a go.


</center>

<figure>
![packages](.\packages.png)
<figcaption>Figure 1: Loaded packages</figcaption>
</figure>

</center>

#### 1.1.0 Observing the data structure
```{r Data sructure, include=TRUE, eval=FALSE}

dim(mobileBanking.Df)
## [1] 43 11
```
The data set has 43 rows with 11 Variables. We therefore explore the data types of each variable/column.

```{r dataTypes,include=TRUE, eval=FALSE}
#Check Categorical VS Numeric Characters----
cat_vars <- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.character))]
cat_vars
##  [1] "Gender"                       "Age.Range"                   
##  [3] "Have.Bak.Account"             "Bank.account.connected.to.MB"
##  [5] "MB.used.for"                  "Importance"                  
##  [7] "Benefit"                      "Bank.Visit"                  
##  [9] "MB.Safety"                    "Influence"                   
## [11] "Satisfaction"

numeric_vars <- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.numeric))]
numeric_vars
## character(0)

```

To identify the data types, we can check for numeric and categorical variables present in the data. In our case, all the variables in our data set are categorical. We will therefore explore the data from a categorical approach rather than numeric. There exists different visualization methods for different data types. Now that we have established the general structure of the data, we can check for missing values, ```NAs```.

```{r, include=TRUE, eval=FALSE}
#Checking data for any missing values
colSums(sapply(mobileBanking.Df, is.na))
##                       Gender                    Age.Range 
##                            0                            0 
##             Have.Bak.Account Bank.account.connected.to.MB 
##                            0                            0 
##                  MB.used.for                   Importance 
##                            0                            0 
##                      Benefit                   Bank.Visit 
##                            0                            0 
##                    MB.Safety                    Influence 
##                            0                            0 
##                 Satisfaction 
##                            0
```

We have no columns with missing values in our data. We can therefore proceed to analysis without worrying about missing values. In a case whereby there exists NA values, one can choose whether to replace the nulls with the most appropriate values or remove the rows with nulls from the data. This is important for later stages of analysis that include data modelling, like Machine Learning. 

<br>
<br>

#### 1.1.1 Data Summary
```{r, include=TRUE, eval=FALSE}
#Data Summary----
summary(mobileBanking.Df)
##     Gender           Age.Range         Have.Bak.Account  
##  Length:43          Length:43          Length:43         
##  Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character  
##  Bank.account.connected.to.MB MB.used.for         Importance       
##  Length:43                    Length:43          Length:43         
##  Class :character             Class :character   Class :character  
##  Mode  :character             Mode  :character   Mode  :character  
##    Benefit           Bank.Visit         MB.Safety        
##  Length:43          Length:43          Length:43         
##  Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character  
##   Influence         Satisfaction      
##  Length:43          Length:43         
##  Class :character   Class :character  
##  Mode  :character   Mode  :character
```
<br>

The base R ```Summary()``` function comes in handy at summarizing data. In our case, there is no statistical measures since all our variables are categorical. Note that the function also specifies the specific data types. There are more than enough ways to inspect data structures in R.

<br>
<br>

### 2.0.0 Getting Insights from the data
#### 2.1.0 Descriptive Statistics For Categorical Data
The main goal of descriptive statistics is to inform data analysts on the main features of either numerical or categorical data, using sample summaries represented as either tables, individual numbers or charts and graphs. Since we only have categorical data, I will illustrate the most used forms of descriptive statistics for the same. However, like I mentioned earlier, there are more than enough ways to analyze data in R.

<br>

##### 2.1.1 Frequencies
**Frequencies** illustrate the number of occurrences or observations of a particular category in data. We use [contigency tables](https://en.wikipedia.org/wiki/Contingency_table) to present this information. In R this can be achieved using the ***table()*** function.

From out data, the total distribution of respondents based on gender looks like this;

```{r contigencyGender, message=FALSE, warning=FALSE,  include=TRUE, eval=FALSE}
#Gender frequencies
#library(kableExtra)
table(mobileBanking.Df$Gender)
## 
## Female   Male 
##     20     23
```

We can illustrate multiple attributes using cross classification tables such as;

```{r crossClassifc, include=TRUE, eval=FALSE}
#library(kableExtra)
# Cross classification counts for gender by Mobile banking safety opinion
table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety)
##         
##          NotAtAll Somewhat Very
##   Female        3       11    6
##   Male          0       19    4
```

Multidimensional tables with three or more categories can also be achieved using the ***ftable()*** . As an example, let's check out the number of respondents based on gender, mobile banking safety opinion and how often they visit the bank.

```{r multidim table, include=TRUE, eval=FALSE}
#Counts by gender, opinion and bank visits
table_ <- table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety, mobileBanking.Df$Bank.Visit)
ftable(table_)
##                  FewTimesAyear OnceMonth
##                                         
## Female NotAtAll              3         0
##        Somewhat             11         0
##        Very                  5         1
## Male   NotAtAll              0         0
##        Somewhat             15         4
##        Very                  4         0
```

<br>

##### 2.1.1 Proportions
Proportions are basically contingency tables represented as percentages. From our previous tables, we can do proportions for the same by applying ***prop.table()*** to output produced by the ***table()** function. Proportions for the above will then be;

```{r Proportions , include=TRUE, eval=FALSE}
#library(kableExtra)
#Gender frequencies proportions
prop.table(table(mobileBanking.Df$Gender))
## 
##    Female      Male 
## 0.4651163 0.5348837

#Percentage idistribution for Gender by mobile banking safety
prop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety))
##         
##            NotAtAll   Somewhat       Very
##   Female 0.06976744 0.25581395 0.13953488
##   Male   0.00000000 0.44186047 0.09302326

#Percentage by gender, opinion and bank visits, rounding off to 2 decimal places
table_ <- table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety, mobileBanking.Df$Bank.Visit)
ftable(round(prop.table(table_),2))
##                  FewTimesAyear OnceMonth
##                                         
## Female NotAtAll           0.07      0.00
##        Somewhat           0.26      0.00
##        Very               0.12      0.02
## Male   NotAtAll           0.00      0.00
##        Somewhat           0.35      0.09
##        Very               0.09      0.00
```

<br>

##### 2.1.2 Marginals
Marginals measure counts across columns or rows in a contingency table. ***Margin.table()*** gives us the frequencies while ***prop.table()*** gives us the percentages. Using our previous examples on frequencies;

```{r marginals, include=TRUE, eval=FALSE}
# FREQUENCY MARGINALS
# row marginals - totals for each gender across mobile banking opinion
margin.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), 1)
## 
## Female   Male 
##     20     23

# colum marginals -  totals for each gender across mobile banking opinion
margin.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), 2)
## 
## NotAtAll Somewhat     Very 
##        3       30       10

# PERCENTAGE MARGINALS
# row marginals - row percentages across gender
prop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), margin = 1)
##         
##          NotAtAll Somewhat     Very
##   Female 0.150000 0.550000 0.300000
##   Male   0.000000 0.826087 0.173913

# colum marginals - column percentages acrossmobile banking opinion
prop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), margin = 2)
##         
##           NotAtAll  Somewhat      Very
##   Female 1.0000000 0.3666667 0.6000000
##   Male   0.0000000 0.6333333 0.4000000
```

#### 2.2.0 Visualizing Distributions
The code chunk bellow is a function that takes in our data set and plots all the present variables in it. Since we have categorical variable only, we will use **bar plots** for visualization. They are the most appropriate for categorical data.

```{r Plotfunction,echo=TRUE}
#Loading Data into R  toc_depth: 2
mobileBanking.Df <- read.csv("J://Personalprojects//Blogsite//data//MobileBankinginKenya.csv", header = TRUE, stringsAsFactors = FALSE )
mobileBanking.Df <- mobileBanking.Df[,-1] #Remove the number column which is Irrelevant

#Check Categorical VS Numeric Characters----
cat_vars <- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.character))]
numeric_vars <- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.numeric))]


####Convert character to factors----
library(data.table)
setDT(mobileBanking.Df)[,(cat_vars) := lapply(.SD, as.factor), .SDcols = cat_vars]

mobileBanking.Df_cat <- mobileBanking.Df[,.SD, .SDcols = cat_vars]
    ##mobileBanking.Df_cont <- mobileBanking.Df[,.SD,.SDcols = numeric_vars]

#Functions for Plots---
library(ggplot2)
library(gridExtra)
plotHist <- function(data_in, i) {
  data <- data.frame(x=data_in[[i]])
  p <- ggplot(data=data, aes(x=factor(x))) + stat_count() + xlab(colnames(data_in)[i]) + theme_light() + 
    theme(axis.text.x = element_text(angle = 90, hjust =1))
  return (p)
}

doPlots <- function(data_in, fun, ii, ncol=3) {
  pp <- list()
  for (i in ii) {
    p <- fun(data_in=data_in, i=i)
    pp <- c(pp, list(p))
  }
  do.call("grid.arrange", c(pp, ncol=ncol))
}

plotDen <- function(data_in, i){
  data <- data.frame(x=data_in[[i]], SalePrice = data_in$SalePrice)
  p <- ggplot(data= data) + geom_line(aes(x = x), stat = 'density', size = 1,alpha = 1.0) +
    xlab(paste0((colnames(data_in)[i]), '\n', 'Skewness: ',round(skewness(data_in[[i]], na.rm = TRUE), 2))) + theme_light() 
  return(p)
  
}

```

<br>



#### Variable Distributions
```{r barplots1, echo= TRUE}
#Plotting categorical values----
#Bar plots
doPlots(mobileBanking.Df_cat, fun = plotHist, ii = 1:4, ncol = 2)


```

<br>

#### Gender
It can be seen that a larger number of respondents were male, this is however by a small margin. If we had a larger data set we could have more female respondents.

<br>

#### Age Range
A majority of respondents were younger guys between age **21-30**, followed by the **31-40** age bracket. The least respondents were those above age **41**. This could be probably because the older people chose not to participate in the survey as opposed to the younger ones, or that they somehow never got to opportunity to do so. A good example is the medium by which the survey was conducted, which the older people didn't have.

<br>

#### Have Bank Account & Linked To Mobile Banking  
All the respondents had bank accounts. A very small number had their business bank accounts linked to mobile banking. Majority had linked their current accounts probably due to the convenience that comes with mobile banking like frequent or timeless withdrawals. 

<br>
<br>

```{r barplots2, echo=FALSE}
#Plotting categorical values----
#Bar plots
 doPlots(mobileBanking.Df_cat, fun = plotHist, ii  = 4:7, ncol = 2)

```

<br>

#### Uses Of Mobile Banking, Importance And Benefits
Most respondents use mobile banking services for making payments. This is followed by cash withdrawals. Airtime purchase and money transfer happen to be the least uses for the service. This could be because they are easily accessible needs unlike cash withdrawal and making payments in terms of mobility convenience.

Most respondents found mobile banking services **very important**, probably owing to the affordable cost charges and good service which could mean less usability issues when using the services.

<br>
<br>


```{r barplots3, echo=FALSE}
#Plotting categorical values----
# #Bar plots
 doPlots(mobileBanking.Df_cat, fun = plotHist, ii = 8:11, ncol = 2)


```

<br>

#### Bank Visits
We had most users who visit their banks a few times a year while the least do it once a month. This means that generally, fewer people visit the bank physically. This could be a major impact of mobile banking services.

<br>

#### Mobile Banking Safety, Influence And Satisfaction
Despite being majorly satisfied by the services, most respondents did not find mobile banking services very safe. It is also seen as time saving which is probably why we had very few bank visits in general. 

<br>

# Conclusion from variable distributions
It can be concluded that mobile banking is mainly preferred by younger people, a majority being of the male gender. However, the only benefit most users find from mobile banking seems to be the convenience it brings. Safety is still a major concern.

<br>
<br>

>That's basically it for exploratory data analysis. I made sure to cover the basics, meaning there's still much to be added on to this; more visualizations, [packages](https://www.researchgate.net/post/What_are_the_best_R_packages_for_exploratory_data_analysis_of_psychological_data) that simplify the whole process etc...This is to be continued. For a detailed documentation on the same, [here's](https://r4ds.had.co.nz/index.html) [Hadley Wickham's](https://twitter.com/hadleywickham?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor) **R for Data Science** book you can use as a reference point.

<br>



<center>

![](https://fontmeme.com/permalink/190129/8b378e9ce35b7a28dd150c4f1d656807.png)

<center>


 
<br>




































































